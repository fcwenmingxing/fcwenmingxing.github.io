---
layout: post
title:  "树模型汇总: 四 RankNet LambdaRank LambdaMart"
date:   2018-05-2 22:14:54
categories: 机器学习
tags: 机器学习 RankNet LambdaRank LambdaMart
excerpt: 机器学习笔记。
mathjax: true
typora-root-url: ..
typora-copy-images-to: ..\inner_ref

---

* content
{:toc}

### IR的预备知识

详细参考：http://blog.sina.com.cn/s/blog_72995dcc01013oo9.html

http://lixinzhang.github.io/xin-xi-jian-suo-zhong-de-ping-jie-zhi-biao-maphe-ndcg.html

本文主要介绍下MAP和NDCG

#### MAP

MAP全称Mean Average Precision，表示平均正确率。其中AP的计算方法如下：

 $$AveP=\frac{\sum_{k=1}^{n}(P(k) \times rel(k))}{相关文档数量}$$ 

其中，$k$为检索结果队列中的排序位置，$P(k)$为前$k$个结果的准确率，即$P(k)=\frac{相关文档数量}{总文档数量}$，$$rel(k)$$表示位置$$k$$的文档是否相关，相关为1，不相关为0。

MAP即是将多个query对应的AP求平均。 $$MAP=\frac{\sum_{q=1}^{Q} AveP(q)}{Q}$$ Q为query的数量。

**举例**

假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP= (0.83+0.45)/2=0.64。” ——[例子来源](http://www.cnblogs.com/ywl925/archive/2013/08/16/3262209.html)

#### NDCG

先说CG（Cumulative Gain，累计增益），

$$
CG_{p} = \sum_{i=1}^{p}rel_i
$$

其中，p为文档在搜索结果列表中的排序位置，$rel_i$为处在该位置文档的等级相关性（graded relevance）。

CG的劣势是等级相关性与位置无关，但这样并不合理，将一个相关性更高的结果替换排在前面相关性较弱的结果，应该更佳，但是CG的表现是两者无差异。因此，引入了DCG（Discounted Cumulative Gain）。

$$
DCG_{p}=\sum_{i=1}^{P} \frac{2^{rel_i} - 1}{log_{2}^{i+1}}
$$

DCG考虑了位置的影响，表示结果位置越靠前的文档，其相关性表现对整体排序质量的影响越大。

然而，DCG仍有一个缺点，**不同query返回的搜索结果数量不同，其DCG的值相差很大，是不可比的**。因此，需要对DCG做一定的归一化，于是有了NDCG（Normalized DCG）。

$$
NDCG_p=\frac{DCG_p}{IDCG_p}
$$

其中，$IDCG_p$为搜索结果按相关性排序之后能得到的最大DCG值。

举例

维基百科上的例子： 搜索结果为文档D1,D2,D3,D4,D5,D6，相关性分数分别为3，2，3，0，1，2，则：
$CG_6 = 3 + 2 + 3 + 0 + 1 + 2=11$
$DCG_6 = \sum_{i=1}^{6} \frac{2^{rel_i}-1}{log_2^{i+1}}=8.10$
按相关性排序可以得到最优结果，即最大DCG为文档按照{3，3，2，2，1，0}排序：
$IDCG_6=8.69$
$NDCG_6 = \frac{DCG_6}{IDCG_6}=0.932$

### RankNet

Ranknet提供了一种基于Pairwise的训练方法，它最早由微软研究院的Chris Burges等人在2005年ICML上的一篇论文Learning to Rank Using Gradient Descent中提出，并被应用在微软的搜索引擎Bing当中。 

#### 样本构造

RankNet属于pairWise， 它的样本是两两数据比较相关性得到的。比如对于一次搜索引擎搜索，召回了N条URL：$U_1,U_2,...,U_n$。样本选取任意两个URL: $U_i,U_j$，得到pair样本： （<$U_i,U_j$>, $S_{ij}$）。元组前面为两个URL的特征，$S_{ij}$取值为$\{0, +1, -1\}$。为1表示$U_i$比$U_j$更相关。

#### 相关性概率

Cost function是RankNet算法的核心，在介绍Cost function前，我们先定义两个概率：预测相关性概率、真实相关性概率。 

**预测相关性概率**  

对于任意一个URL对$(U_i,U_j)$，模型输出的score分别为$s_i$和$s_j$，那么根据模型的预测，$U_i$比$U_j$与Query**更相关的概率为**：
$$
P_{ij} = P(U_i>U_j) = {1\over {1+e^{-\sigma(s_i-s_j)}}}
$$
由于RankNet使用的模型一般为神经网络，根据经验sigmoid函数能提供一个比较好的概率评估。参数$\sigma$决定sigmoid函数的形状，对最终结果影响不大。 

**真实相关性概率** 

对于训练数据中的$U_i$和$U_j$，它们都包含有一个与Query相关性的真实label，比如$U_i$与Query的相关性label为good，$U_j$与Query的相关性label为bad，那么显然$U_i$比$U_j$更相关。我们定义$\overline p_{ij}$为$U_i$比$U_j$**更相关的真实概率**，有
$$
\overline p_{ij} = {1\over2 }(1+S_{ij})
$$
如果$U_i$比$U_j$更相关，那么$S_{ij}=1$；如果$U_i$不如$U_j$相关，那么$S_{ij}=-1$；如果$U_i$、$U_j$与Query的相关程度相同，那么$S_{ij}=0$。 

#### 代价函数

对于一个排序，RankNet从各个URL的相对关系来评价排序结果的好坏，排序的效果越好，那么有错误相对关系的pair就越少。所谓错误的相对关系即如果根据模型输出$U_i$排在$U_j$前面，但真实label为$U_i$的相关性小于$U_j$，那么就记一个错误pair，RankNet就是以错误的pair最少为优化目标。对于每一个pair，我们使用交叉熵来度量其预测代价，即： 
$$
C_{ij} = -\overline P_{ij}logP_{ij}-(1-\overline P_{ij})log(1-P_{ij})
$$
化简
$$
\begin{align}  C_{ij}  &= -{1\over2}(1+S_{ij})log{1\over 1+e^{-\sigma(s_{i}-s_{j})}}-{1\over2}(1-S_{ij})log{e^{-\sigma(s_i-s_j)}\over 1+e^{-\sigma(s_i-s_j)}} \\&=-{1\over2}(1+S_{ij})log{1\over 1+e^{-\sigma(s_{i}-s_{j})}}-{1\over2}(1-S_{ij})[-\sigma(s_i-s_j)+log{1\over 1+e^{-\sigma(s_i-s_j)}}]\\&={1\over2}(1-S_{ij})\sigma(s_i-s_j)+log(1+e^{-\sigma(s_i-s_j)})\end{align}
$$


### 参考资料

[RankNet与LambdaRank](https://blog.csdn.net/u014374284/article/details/49385065)