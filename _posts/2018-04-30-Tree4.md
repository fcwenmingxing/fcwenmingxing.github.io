---
layout: post
title:  "树模型汇总: 四 RankNet LambdaRank LambdaMart"
date:   2018-05-15 22:14:54
categories: 机器学习
tags: 机器学习 RankNet LambdaRank LambdaMart
excerpt: 机器学习笔记。
mathjax: true
typora-root-url: ..
typora-copy-images-to: ..\inner_ref

---

* content
{:toc}

### IR的预备知识

详细参考：http://blog.sina.com.cn/s/blog_72995dcc01013oo9.html

http://lixinzhang.github.io/xin-xi-jian-suo-zhong-de-ping-jie-zhi-biao-maphe-ndcg.html

本文主要介绍下MAP和NDCG

#### MAP

MAP全称Mean Average Precision，表示平均正确率。其中AP的计算方法如下：

 $$AveP=\frac{\sum_{k=1}^{n}(P(k) \times rel(k))}{相关文档数量}$$ 

其中，$k$为检索结果队列中的排序位置，$P(k)$为前$k$个结果的准确率，即$P(k)=\frac{相关文档数量}{总文档数量}$，$$rel(k)$$表示位置$$k$$的文档是否相关，相关为1，不相关为0。

MAP即是将多个query对应的AP求平均。 $$MAP=\frac{\sum_{q=1}^{Q} AveP(q)}{Q}$$ Q为query的数量。

**举例**

假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP= (0.83+0.45)/2=0.64。” ——[例子来源](http://www.cnblogs.com/ywl925/archive/2013/08/16/3262209.html)

#### NDCG

先说CG（Cumulative Gain，累计增益），

$$
CG_{p} = \sum_{i=1}^{p}rel_i
$$

其中，p为文档在搜索结果列表中的排序位置，$rel_i$为处在该位置文档的等级相关性（graded relevance）。

CG的劣势是等级相关性与位置无关，但这样并不合理，将一个相关性更高的结果替换排在前面相关性较弱的结果，应该更佳，但是CG的表现是两者无差异。因此，引入了DCG（Discounted Cumulative Gain）。

$$
DCG_{p}=\sum_{i=1}^{P} \frac{2^{rel_i} - 1}{log_{2}^{i+1}}
$$

DCG考虑了位置的影响，表示结果位置越靠前的文档，其相关性表现对整体排序质量的影响越大。

然而，DCG仍有一个缺点，**不同query返回的搜索结果数量不同，其DCG的值相差很大，是不可比的**。因此，需要对DCG做一定的归一化，于是有了NDCG（Normalized DCG）。

$$
NDCG_p=\frac{DCG_p}{IDCG_p}
$$

其中，$IDCG_p$为搜索结果按相关性排序之后能得到的最大DCG值。

举例

维基百科上的例子： 搜索结果为文档D1,D2,D3,D4,D5,D6，相关性分数分别为3，2，3，0，1，2，则：
$CG_6 = 3 + 2 + 3 + 0 + 1 + 2=11$
$DCG_6 = \sum_{i=1}^{6} \frac{2^{rel_i}-1}{log_2^{i+1}}=8.10$
按相关性排序可以得到最优结果，即最大DCG为文档按照{3，3，2，2，1，0}排序：
$IDCG_6=8.69$
$NDCG_6 = \frac{DCG_6}{IDCG_6}=0.932$

### RankNet

Ranknet提供了一种基于Pairwise的训练方法，它最早由微软研究院的Chris Burges等人在2005年ICML上的一篇论文Learning to Rank Using Gradient Descent中提出，并被应用在微软的搜索引擎Bing当中。 

#### 样本构造

RankNet属于pairWise， 它的样本是两两数据比较相关性得到的。比如对于一次搜索引擎搜索，召回了N条URL：$U_1,U_2,...,U_n$。样本选取任意两个URL: $U_i,U_j$，得到pair样本： （<$U_i,U_j$>, $S_{ij}$）。元组前面为两个URL的特征，$S_{ij}$取值为$\{0, +1, -1\}$。为1表示$U_i$比$U_j$更相关。

#### 相关性概率

Cost function是RankNet算法的核心，在介绍Cost function前，我们先定义两个概率：预测相关性概率、真实相关性概率。 

**预测相关性概率**  

对于任意一个URL对$(U_i,U_j)$，模型输出的score分别为$s_i$和$s_j$，那么根据模型的预测，$U_i$比$U_j$与Query**更相关的概率为**：
$$
P_{ij} = P(U_i>U_j) = {1\over {1+e^{-\sigma(s_i-s_j)}}}
$$
由于RankNet使用的模型一般为神经网络，根据经验sigmoid函数能提供一个比较好的概率评估。参数$\sigma$决定sigmoid函数的形状，对最终结果影响不大。 

**真实相关性概率** 

对于训练数据中的$U_i$和$U_j$，它们都包含有一个与Query相关性的真实label，比如$U_i$与Query的相关性label为good，$U_j$与Query的相关性label为bad，那么显然$U_i$比$U_j$更相关。我们定义$\overline p_{ij}$为$U_i$比$U_j$**更相关的真实概率**，有
$$
\overline p_{ij} = {1\over2 }(1+S_{ij})
$$
如果$U_i$比$U_j$更相关，那么$S_{ij}=1$；如果$U_i$不如$U_j$相关，那么$S_{ij}=-1$；如果$U_i$、$U_j$与Query的相关程度相同，那么$S_{ij}=0$。 

#### 代价函数

对于一个排序，RankNet从各个URL的相对关系来评价排序结果的好坏，排序的效果越好，那么有错误相对关系的pair就越少。所谓错误的相对关系即如果根据模型输出$U_i$排在$U_j$前面，但真实label为$U_i$的相关性小于$U_j$，那么就记一个错误pair，RankNet就是以错误的pair最少为优化目标。对于每一个pair，我们使用交叉熵来度量其预测代价，即： 
$$
C_{ij} = -\overline P_{ij}logP_{ij}-(1-\overline P_{ij})log(1-P_{ij})
$$
化简
$$
\begin{align}  C_{ij}  &= -{1\over2}(1+S_{ij})log{1\over 1+e^{-\sigma(s_{i}-s_{j})}}-{1\over2}(1-S_{ij})log{e^{-\sigma(s_i-s_j)}\over 1+e^{-\sigma(s_i-s_j)}} \\&=-{1\over2}(1+S_{ij})log{1\over 1+e^{-\sigma(s_{i}-s_{j})}}-{1\over2}(1-S_{ij})[-\sigma(s_i-s_j)+log{1\over 1+e^{-\sigma(s_i-s_j)}}]\\&={1\over2}(1-S_{ij})\sigma(s_i-s_j)+log(1+e^{-\sigma(s_i-s_j)})\end{align}
$$
![xx](/inner_ref/2018-04-30-Tree/20151024210741613) 

当$S_{ij}=1$时,我们有:

![1526297017176](/inner_ref/2018-04-30-Tree/1526297017176.png)

当$S_{ij}=-1$时:

![1526297061460](/inner_ref/2018-04-30-Tree/1526297061460.png)

该代价函数有以下特点：

> 当两个相关性不同的文档算出来的模型分数相同时，损失函数的值大于0，仍会对这对pair做惩罚，使他们的排序位置区分开
>
> 损失函数是一个类线性函数，可以有效减少异常样本数据对模型的影响，因此具有鲁棒性

总代价
$$
C = {\sum_{(i,j)\in I} }C_{ij}
$$
$I$表示所有URL pari的集合，且每个pair仅包含一次。

#### 梯度下降迭代

我们获得了一个可微的代价函数，下面我们就可以用梯度下降法来迭代更新模型参数$w_k$了，即 
$$
w_k \rightarrow w_k-\eta {\partial C \over \partial w_k}
$$
$\eta$为步长，代价C沿负梯度方向变化.

我们对${\partial C \over \partial w_k}$继续分解
$$
{\partial C \over \partial w_k}=\underset{(i,j)\in I}{\sum}( {\partial C_{ij} \over \partial s_i} {\partial s_i \over \partial w_k}+{\partial C_{ij} \over \partial s_j} {\partial s_j \over \partial w_k})
$$
其中
$$
{\partial C_{ij} \over \partial s_i} = \sigma ({1 \over 2}(1-S_{ij})-{1\over 1+e^{\sigma(s_i-s_j)}}) = -{\partial C_{ij} \over \partial s_j}
$$
我们令$\lambda_{ij} = {\partial C_{ij} \over \partial s_i} = \sigma ({1 \over 2}(1-S_{ij})-{1\over 1+e^{\sigma(s_i-s_j)}})$，有
$$
\begin{align}{\partial C \over \partial w_k} &= \underset{(i,j)\in I}{\sum}\sigma ({1 \over 2}(1-S_{ij})-{1\over 1+e^{\sigma(s_i-s_j)}})({\partial s_i \over \partial w_k}-{\partial s_j \over \partial w_k}) \\ &=\underset{(i,j)\in I}{\sum}\lambda_{ij}({\partial s_i \over \partial w_k}-{\partial s_j \over \partial w_k}) \\ &=\underset{i}{\sum}\lambda_i {\partial s_i \over \partial w_k}\end{align}
$$
下面我们来看看这个$\lambda_i$是什么。前面讲过集合$I$中只包含label不同的URL的集合，且每个pair仅包含一次，即$(U_i,U_j)$与$(U_j,U_i)$等价。为方便起见，我们假设I中只包含$(U_i,U_j)$表示$U_i$相关性大于$U_j$的pair，即I中的pair均满足$S_{ij}=1$，那么
$$
\lambda_i = \underset {j:(i,j)\in I}{\sum}\lambda_{ij} -  \underset {j:(j,i)\in I}{\sum}\lambda_{ij}
$$
这个写法是Burges的paper上的写法，我对此好久都没有理清，下面我们用一个实际的例子来看：有三个URL，其真实相关性满足$U_1>U_2>U_3$，那么集合$I$中就包含${(1,2), (1,3), (2,3)}$共三个pair 
$$
{\partial C \over \partial w_k}=(\lambda_{12}{\partial s_1 \over \partial w_k}-\lambda_{12}{\partial s_2 \over \partial w_k})+(\lambda_{13}{\partial s_1 \over \partial w_k}-\lambda_{13}{\partial s_3 \over \partial w_k})+(\lambda_{23}{\partial s_2 \over \partial w_k}-\lambda_{23}{\partial s_3 \over \partial w_k})
$$
显然$\lambda_1 =\lambda_{12}+\lambda_{13}$，$\lambda_2 =\lambda_{23}-\lambda_{12}$，$\lambda_3 =-\lambda_{13}-\lambda_{23}$，因此我所理解的$\lambda_i$应为
$$
\lambda_i = \underset {j:(i,j)\in I}{\sum}\lambda_{ij} -  \underset {k:(k,i)\in I}{\sum}\lambda_{ki}
$$
$\lambda_i$**决定着第$i$个URL在迭代中的移动方向和幅度**，比如:$S_{ij}=1$表示$U_i$比$U_j$更相关，如果$s_i$的值低于$s_j$的值(也就是模型判断错误), 此时$\lambda_{ij}$的值就是正数. 所以$\lambda_i$就应该向正梯度方向移动(也就是第i个样本的预测值应该提高)

#### LambdaRank

上面我们介绍了以错误pair最少为优化目标的RankNet算法，然而许多时候仅以错误pair数来评价排序的好坏是不够的，像NDCG或者ERR等评价指标就只关注top k个结果的排序，当我们采用RankNet算法时，往往无法以这些指标为优化目标进行迭代，以下图为例： 

![](/inner_ref/2018-04-30-Tree/20151025154133156)




### 参考资料

[RankNet与LambdaRank](https://blog.csdn.net/u014374284/article/details/49385065)